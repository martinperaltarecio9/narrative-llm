{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b74c623d",
   "metadata": {},
   "source": [
    "# Entrenamiento del Discriminador."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86027a04",
   "metadata": {},
   "source": [
    "Este notebook entrena un clasificador binario basado en RoBERTa para distinguir textos\n",
    "estilo Shakespeare (positivos) de textos no Shakespeare (negativos).\n",
    "\n",
    "Los negativos incluyen tanto controles gruesos (otros géneros/autores)\n",
    "como controles finos (textos literarios más cercanos en estilo).\n",
    "\n",
    "El modelo entrenado se utiliza luego para obtener una métrica de qué tan eficiente fue el finetune del modelo Mistral 7B."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5cdc814",
   "metadata": {},
   "source": [
    "## 0. Dependencias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "526c7db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q transformers datasets accelerate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79754a7e",
   "metadata": {},
   "source": [
    "## 1. Imports y rutas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a38ebce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datasets import Dataset\n",
    "\n",
    "# rutas\n",
    "POS_DIR = \"/content/drive/MyDrive/StoryWriter/Data/Training_data/clasificator_train/positivos\"\n",
    "NEG_DIR = \"/content/drive/MyDrive/StoryWriter/Data/Training_data/clasificator_train/negativos_gruesos\"\n",
    "NEGF_DIR = \"/content/drive/MyDrive/StoryWriter/Data/Training_data/clasificator_train/negativos_finos\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10c3d26c",
   "metadata": {},
   "source": [
    "## 3. Carga de textos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aac16d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cargar_textos(carpeta, etiqueta):\n",
    "    \"\"\"\n",
    "    Carga archivos .txt de una carpeta y asigna una etiqueta binaria.\n",
    "    etiqueta = 1 -> positivo (Shakespeare-like)\n",
    "    etiqueta = 0 -> negativo (no Shakespeare)\n",
    "    \"\"\"\n",
    "    ejemplos = []\n",
    "    for fname in os.listdir(carpeta):\n",
    "        if fname.endswith(\".txt\"):\n",
    "            ruta = os.path.join(carpeta, fname)\n",
    "            with open(ruta, \"r\", encoding=\"utf-8\") as f:\n",
    "                texto = f.read()\n",
    "            ejemplos.append({\"text\": texto, \"label\": etiqueta})\n",
    "    return ejemplos\n",
    "\n",
    "positivos = cargar_textos(POS_DIR, 1)\n",
    "negativos_gruesos = cargar_textos(NEG_DIR, 0)\n",
    "negativos_finos = cargar_textos(NEGF_DIR, 0)\n",
    "\n",
    "# balance simple: usar la misma cantidad de negativos gruesos que finos\n",
    "negativos_gruesos = negativos_gruesos[len(negativos_finos):]\n",
    "negativos = negativos_gruesos + negativos_finos\n",
    "\n",
    "datos = positivos + negativos\n",
    "\n",
    "print(\"Total de ejemplos de entrenamiento:\", len(datos))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64bb842a",
   "metadata": {},
   "source": [
    "## 4. Construcción del dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5328fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset.from_list(datos)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be17f06d",
   "metadata": {},
   "source": [
    "## 5. Tokenización."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "642a43e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"roberta-base\")\n",
    "\n",
    "MAX_LENGTH = 512\n",
    "\n",
    "def tokenize(batch):\n",
    "    return tokenizer(\n",
    "        batch[\"text\"],\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "        max_length=MAX_LENGTH\n",
    "    )\n",
    "\n",
    "tokenized = dataset.map(tokenize, batched=True)\n",
    "tokenized = tokenized.remove_columns([\"text\"])\n",
    "tokenized.set_format(\"torch\")\n",
    "\n",
    "# debug en CUDA (para Colab)\n",
    "import os\n",
    "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a37e949",
   "metadata": {},
   "source": [
    "## 6. Modelo y configuración del entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2aec3cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import (\n",
    "    AutoModelForSequenceClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer\n",
    ")\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"roberta-base\",\n",
    "    num_labels=2\n",
    ")\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"/content/drive/MyDrive/StoryWriter/Clasificador/Grueso+fino\",\n",
    "    learning_rate=2e-5,\n",
    "    num_train_epochs=4,\n",
    "    per_device_train_batch_size=8,\n",
    "    weight_decay=0.01,\n",
    "    logging_steps=100,\n",
    "    save_total_limit=2,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized,\n",
    "    tokenizer=tokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ad913b6",
   "metadata": {},
   "source": [
    "## 7. Entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0be9a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abd7f44f",
   "metadata": {},
   "source": [
    "## 8. Guardado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ec845e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = \"/content/drive/MyDrive/StoryWriter/Clasificador/Grueso+fino\"\n",
    "\n",
    "trainer.save_model(save_dir)\n",
    "tokenizer.save_pretrained(save_dir)\n",
    "\n",
    "print(\"Modelo guardado en:\", save_dir)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
